{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 3: Dataset de entrenamiento y de prueba\n",
    "\n",
    "### 1. Objetivos:\n",
    "    - Aprender cómo dividir nuestro dataset en dos para entrenar nuestro modelo y probarlo utilizando diferentes datos.\n",
    "    - Aprender a entrenar un modelo de Regresión Linear Múltiple\n",
    " \n",
    "---\n",
    "    \n",
    "### 2. Desarrollo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Regresión Linear Múltiple\n",
    "\n",
    "Vamos a combinar esta técnica con un modelo de Regresión Linear Múltiple. La Regresión Linear Múltiple es básicamente lo mismo que la Regresión Linear Simple, con la diferencia de que podemos utilizar más de una variable independiente y dependiente. Es más difícil (y a veces en realidad imposible) visualizar la función lineal que obtenemos a través de una Regresión Linear Múltiple, puesto que la línea que representa es una línea que se encuentra en ¡más de dos dimensiones! Pero el concepto es el mismo: utilizamos una o más variables independientes para entrenar un modelo, con el objetivo de encontrar una función lineal que pueda predecir a una o más variables dependientes.\n",
    "\n",
    "Por suerte, el proceso de entrenamiento es en realidad el mismo, así que podemos concentrarnos en aprender a dividir nuestro dataset en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Datasets/diabetes-clean.csv', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar este método de `scikit learn` para dividir nuestro dataset en dos. Voy a entrenar un modelo para intentar predecir los niveles de insulina en una persona utilizando las variables 'glucose' y 'skin_thickness', así que mi variable dependiente será 'glucose' y mis variables independientes serán las otras dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['glucose', 'skin_thickness']]\n",
    "y = df['insulin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, X_test, y_training, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota el tamaño del dataset de prueba (30% del total) y que estamos revolviendo el dataset aleatoriamente antes de realizar la división."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, nuestro R2 es menor incluso que los coeficientes de correlación que tienen ambas variables independientes con la dependiente. Esto significa que nuestra precisión no es necesariamente 'acumulativa'.\n",
    "\n",
    "Mira lo que sucede si entrenamos nuestro modelo sin hacer la división de entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_2 = LinearRegression()\n",
    "lr_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_2.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un score ligeramente mejor. Aunque en este caso no resulta tan relevante porque de todas maneras el poder predictivo es prácticamente nulo, nos demuestra que el modelo puede a veces aprender a predecir correctamente los datos que conoce y generalizar muy mal a datos que no conoce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
